{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from load_data import load_mnist\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import seaborn as sns\n",
    "\n",
    "#palette=sns.color_palette(\"cubehelix\", 10)\n",
    "palette=sns.color_palette(\"magma\", 10)\n",
    "#palette=sns.color_palette(\"viridis\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "1797\n"
     ]
    }
   ],
   "source": [
    "#Load the data\n",
    "X, y = load_digits(return_X_y=True) #X a np array of size (1797, 64) and y the corresponding label\n",
    "print(X.shape)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for easy plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots\n",
    "\n",
    "def plot_tsne(xy, hue='hue', legend = \"full\", palette = palette):\n",
    "    sns.set(rc={'figure.figsize':(10,10)})\n",
    "    #palette=sns.color_palette(\"cubehelix\", 10)\n",
    "    palette=sns.color_palette(\"magma\", 10)\n",
    "    #palette=sns.color_palette(\"viridis\", 10)\n",
    "    fig = sns.scatterplot(xy[:,0], xy[:,1],\n",
    "                hue = hue,\n",
    "                legend = \"full\",\n",
    "                palette = palette) # don't use edges\n",
    "    plt.show()\n",
    "    \n",
    "#plot_tsne(X_embedded, hue = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_distances(X):\n",
    "    D_squared = np.sum((X[None,:] - X[:, None])**2, -1)\n",
    "    return -D_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pair_distances(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pair_distances(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for equation 1 and 4 \n",
    "def quotient(distances):\n",
    "    # Subtract max for numerical stability\n",
    "    e_x = np.exp(distances - np.max(distances, axis=1).reshape([-1, 1]))\n",
    "\n",
    "    # Diagonal 0.\n",
    "    np.fill_diagonal(e_x, 0.)\n",
    "\n",
    "    # Add a tiny constant for stability of log we take later\n",
    "    e_x = e_x + 1e-6  # numerical stability\n",
    "\n",
    "    return e_x / e_x.sum(axis=1).reshape([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#None for q_ij and sigmas activated for p_ij\n",
    "def compute_proba_matrix(distances,sigmas=None):\n",
    "    if sigmas.all()==None: \n",
    "        return quotient(distances)\n",
    "    else:\n",
    "        return quotient(distances / (2*np.square(sigmas.reshape((-1, 1))))) #WARNING: HERE WE ARE USING THE STANDARD DEVIATION (?) INSTEAD OF THE VARIANCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_proba_matrix(distances,sigmas=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_crowd(P):\n",
    "    N = P.shape[0]\n",
    "    return (P+P.T)/2*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the low dimesional map qij using ec 4\n",
    "def Q_table(Y):\n",
    "    distances_low_dim=pair_distances(Y)\n",
    "    nom = np.linalg.inv(1.-distances_low_dim)\n",
    "    # Fill diagonal with zeroes so q_ii = 0\n",
    "    np.fill_diagonal(exp_distances, 0.) # WARNING: NUMERICAL STABILITY\n",
    "    deno = np.linalg.inv(np.sum(1.-exp_distances))\n",
    "    return nom/deno\n",
    "\n",
    "def q_joint(Y):\n",
    "    \"\"\"Given low-dimensional representations Y, compute\n",
    "    matrix of joint probabilities with entries q_ij.\"\"\"\n",
    "    # Get the distances from every point to every other\n",
    "    distances = neg_squared_euc_dists(Y)\n",
    "    # Take the elementwise exponent\n",
    "    exp_distances = np.exp(distances)\n",
    "    # Fill diagonal with zeroes so q_ii = 0\n",
    "    np.fill_diagonal(exp_distances, 0.)\n",
    "    # Divide by the sum of the entire exponentiated matrix\n",
    "    return exp_distances / np.sum(exp_distances), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_table(X,our_perplexity):\n",
    "    distances_high_dim = pair_distances(X)\n",
    "    print(f\"Distances {distances_high_dim}\")\n",
    "    \n",
    "    sigmas=find_sigmas(distances_high_dim,our_perplexity)\n",
    "    print(f\"Sigmas {sigmas}\")\n",
    "    P=compute_proba_matrix(distances_high_dim,sigmas)\n",
    "    return solve_crowd(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def compute_gradient(P,Q,Y):\n",
    "    \n",
    "#    pq_diff = P - Q\n",
    "#    pq_expanded = np.expand_dims(pq_diff, 2)\n",
    "#    y_diffs = np.expand_dims(Y, 1) - np.expand_dims(Y, 0)\n",
    "#    \n",
    "#    distances_low_dim=pair_distances(Y)\n",
    "#    aux = np.linalg.inv(np.exp(1.-distances))\n",
    "#    distances_low_expanded = np.expand_dims(aux, 2)\n",
    "#    \n",
    "#    y_diffs_wt = y_diffs * distances_low_expanded#\n",
    "#\n",
    "#    # Multiply then sum over j's\n",
    "#    grad = 4. * (pq_expanded * y_diffs_wt).sum(1)\n",
    "#    \n",
    "#    return grad\n",
    "\n",
    "def gradient(p, q, y):\n",
    "    \"\"\"Computes the gradient\"\"\"\n",
    "    N = p.shape[0]\n",
    "    m = y.shape[1]\n",
    "    grad = np.zeros((N,m))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            grad[i,:] += 4*(p[i,j] - q[i,j])*(y[i] - y[j])*(1 + np.linalg.norm(y[i] - y[j])**2)**(-1)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_sne(X,classes,our_perplexity, num_iter, nu, alpha,P):\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    print(f\"Number of points: {N}\")\n",
    "    #P = P_table(X,our_perplexity)\n",
    "    #print(f\"P table {P}\")\n",
    "    np.random.seed(10)\n",
    "    Y = np.random.normal(loc=0.0, scale=1e-4, size=(N,2))\n",
    "    Y_m2 = Y.copy()\n",
    "    Y_m1 = Y.copy()\n",
    "    for i in range(num_iter):\n",
    "        print(i)\n",
    "        Q= Q_table(Y) #compute low dimensional affinities\n",
    "        print(f\"Q table {Q}\")\n",
    "        grad = compute_gradient(P,Q,Y) # compute gradient\n",
    "        print(f\"Print gradient: {grad}\")\n",
    "        Y = Y + nu*grad + alpha*(Y_m1-Y_m2)#set y_i's\n",
    "        Y_m2 = Y_m1.copy()\n",
    "        Y_m1 = Y.copy()\n",
    "    \n",
    "    return Y #low dimensional representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section to compute the sigmas.\n",
    "\n",
    "This is use to compute p_j|i given that we need one sigma per point in the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First a binary search \n",
    "\n",
    "#To locate the index of the suitable sigma in array and later on\n",
    "def binary_search(array,target,tol=1e-10,max_iter=1000,lower=1e-20,upper=1000.):\n",
    "    for i in range(max_iter):\n",
    "        guess = ((lower + upper) / 2.) + lower\n",
    "        val = array(guess)\n",
    "        if val > target:\n",
    "            upper = guess\n",
    "        else:\n",
    "            lower = guess\n",
    "        if np.abs(val - target) <= tol:\n",
    "            break\n",
    "    return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The remaining parameter to be selected is the variance si of the Gaussian that is centered over\n",
    "#each high-dimensional datapoint, xi. It is not likely that there is a single value of si that is optimal\n",
    "#for all datapoints in the data set because the density of the data is likely to vary. In dense regions,\n",
    "#a smaller value of si is usually more appropriate than in sparser regions. Any particular value of\n",
    "#si induces a probability distribution, Pi, over all of the other datapoints. This distribution has an\n",
    "#entropy which increases as si increases. SNE performs a binary search for the value of si that\n",
    "#produces a Pi with a fixed perplexity that is specified by the user\n",
    "\n",
    "def calc_perplex(distances,sigmas):\n",
    "    proba_matrix=compute_proba_matrix(distances,sigmas=sigmas)\n",
    "    logar=np.log2(proba_matrix)\n",
    "    entropy = -np.sum(proba_matrix*logar,1)\n",
    "    perplexity = 2**entropy\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNE performs a binary searh for the value of sigma_i that ptoduces a P_i with a\n",
    "#fixed perplexity that is specified by the user\n",
    "def find_sigmas(distances,our_perplexity):\n",
    "    sigmas=np.zeros(distances.shape[0])\n",
    "    # For each row of the matrix (each point in our dataset)\n",
    "    for i in range(distances.shape[0]):\n",
    "        # Make fn that returns perplexity of this row given sigma\n",
    "        eval_sigma_fn = lambda sigma: \\\n",
    "            calc_perplex(distances[i:i+1, :], np.array(sigma))\n",
    "        # Binary search over sigmas to achieve target perplexity\n",
    "        correct_sigma = binary_search(eval_sigma_fn, our_perplexity,tol=1e-10,max_iter=1000,lower=1e-20,upper=1000.)\n",
    "        # Save the correct sigma \n",
    "        sigmas[i]=correct_sigma\n",
    "        print(sigmas)\n",
    "    return np.array(sigmas) #Do we need the np.array??? sigmas is already an array, isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement t-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances [[   -0. -3547. -2930. ... -2538. -1374. -2212.]\n",
      " [-3547.    -0. -1733. ... -1489. -2359. -2533.]\n",
      " [-2930. -1733.    -0. ... -1470. -2578. -1932.]\n",
      " ...\n",
      " [-2538. -1489. -1470. ...    -0. -1950.  -834.]\n",
      " [-1374. -2359. -2578. ... -1950.    -0. -1554.]\n",
      " [-2212. -2533. -1932. ...  -834. -1554.    -0.]]\n",
      "Sigmas [11.71875 23.4375  23.4375  ... 23.4375  23.4375  23.4375 ]\n",
      "P table [[5.90334911e-05 1.36838233e-01 2.92356657e-01 ... 3.24885255e-01\n",
      "  1.05446811e+00 4.30068230e-01]\n",
      " [1.36838233e-01 6.90314510e-06 1.57978788e+00 ... 1.72663949e+00\n",
      "  7.52428291e-01 6.58199223e-01]\n",
      " [2.92356657e-01 1.57978788e+00 8.39678158e-06 ... 1.95269810e+00\n",
      "  6.87915001e-01 1.26612669e+00]\n",
      " ...\n",
      " [3.24885255e-01 1.72663949e+00 1.95269810e+00 ... 6.48863668e-06\n",
      "  1.05667231e+00 2.99311568e+00]\n",
      " [1.05446811e+00 7.52428291e-01 6.87915001e-01 ... 1.05667231e+00\n",
      "  5.97978594e-06 1.49235513e+00]\n",
      " [4.30068230e-01 6.58199223e-01 1.26612669e+00 ... 2.99311568e+00\n",
      "  1.49235513e+00 6.30036112e-06]]\n",
      "Number of points: 1797\n",
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'distances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-a5f03e473b16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Fit SNE or t-SNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m X_embeded = t_sne(X=X,classes=y,our_perplexity=PERPLEXITY, num_iter=NUM_ITERS, \n\u001b[0m\u001b[0;32m     19\u001b[0m           nu=LEARNING_RATE, alpha=MOMENTUM, P=P)\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-ca7bbcebfb9a>\u001b[0m in \u001b[0;36mt_sne\u001b[1;34m(X, classes, our_perplexity, num_iter, nu, alpha, P)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mQ\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mQ_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#compute low dimensional affinities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Q table {Q}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# compute gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-23c658e52a50>\u001b[0m in \u001b[0;36mQ_table\u001b[1;34m(Y)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mQ_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdistances_low_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpair_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mnom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Fill diagonal with zeroes so q_ii = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_diagonal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_distances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# WARNING: NUMERICAL STABILITY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'distances' is not defined"
     ]
    }
   ],
   "source": [
    "# Set global parameters\n",
    "#NUM_POINTS = 100            # Number of samples from MNIST\n",
    "#CLASSES_TO_USE = [0, 1, 8]  # MNIST classes to use\n",
    "PERPLEXITY = 30                   # Random seed\n",
    "MOMENTUM = 0.9              #alpha  \n",
    "LEARNING_RATE = 10.         # nu\n",
    "NUM_ITERS = 1             # Num iterations to train for  \n",
    "\n",
    "\n",
    "# numpy RandomState for reproducibility\n",
    "rng = np.random.RandomState(1)\n",
    "\n",
    "# Obtain matrix of joint probabilities p_ij\n",
    "P = P_table(X, PERPLEXITY)\n",
    "print(f\"P table {P}\")\n",
    "\n",
    "# Fit SNE or t-SNE\n",
    "X_embeded = t_sne(X=X,classes=y,our_perplexity=PERPLEXITY, num_iter=NUM_ITERS, \n",
    "          nu=LEARNING_RATE, alpha=MOMENTUM, P=P)\n",
    "\n",
    "import winsound\n",
    "duration = 700  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "duration = 500  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beep():\n",
    "    print \"\\a\"\n",
    " \n",
    "beep()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
